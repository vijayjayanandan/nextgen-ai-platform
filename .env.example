# Application Configuration
PROJECT_NAME=IRCC AI Platform
ENVIRONMENT=development
DEBUG=true
API_V1_STR=/api/v1

# Security
SECRET_KEY=your-secret-key-here
ACCESS_TOKEN_EXPIRE_MINUTES=480
ALGORITHM=HS256
ALLOWED_HOSTS=["http://localhost:3000","http://127.0.0.1:3000"]

# Database
POSTGRES_SERVER=localhost
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=ircc_ai_platform

# Vector Database
VECTOR_DB_TYPE=pinecone
VECTOR_DB_URI=https://ircc-documents-izi1icy.svc.aped-4627-b74a.pinecone.io
VECTOR_DB_API_KEY=pcsk_28G6m7_2C6smHBE16GHWU2mA5G5vtW7aWSiqygbTz4WUQ4QmSXNf2NNKpTfhV4DarVfXvn
VECTOR_DB_NAMESPACE=ircc-documents

# LLM Services
OPENAI_API_KEY=your-openai-api-key
ANTHROPIC_API_KEY=your-anthropic-api-key
OPENAI_API_BASE=https://api.openai.com/v1
ANTHROPIC_API_BASE=https://api.anthropic.com

# Feature Flags
ENABLE_RETRIEVAL_AUGMENTATION=true
ENABLE_CONTENT_FILTERING=false
ENABLE_EXPLANATION=true

# Performance
MAX_CONCURRENT_REQUESTS=100
REQUEST_TIMEOUT_SECONDS=120

# Logging
LOG_LEVEL=INFO
ENABLE_AUDIT_LOGGING=true

# IRCC System Integration
GCDOCS_API_ENDPOINT=
GCMS_API_ENDPOINT=
DYNAMICS_API_ENDPOINT=

# On-Premises Model Configuration
ON_PREM_MODEL_ENABLED=true
ON_PREM_MODEL_ENDPOINT=http://localhost:11434

# On-Premises Model Endpoints (override defaults in config.py)
# Uncomment and modify as needed
# LLAMA_7B_ENDPOINT=http://llama-vm.canadacentral.azure.com:8000/v1
# LLAMA_70B_ENDPOINT=http://llama-vm.canadacentral.azure.com:8001/v1
# DEEPSEEK_7B_ENDPOINT=http://deepseek-vm.canadacentral.azure.com:8000/v1
# DEEPSEEK_CODER_ENDPOINT=http://deepseek-vm.canadacentral.azure.com:8001/v1
