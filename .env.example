# Application Configuration
PROJECT_NAME=IRCC AI Platform
ENVIRONMENT=development
DEBUG=true
API_V1_STR=/api/v1

# Security
SECRET_KEY=your-secret-key-here
ACCESS_TOKEN_EXPIRE_MINUTES=480  # 8 hours
ALGORITHM=HS256
ALLOWED_HOSTS=*

# Database
POSTGRES_SERVER=localhost
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=ircc_ai_platform

# Vector Database
VECTOR_DB_TYPE=pinecone
VECTOR_DB_URI=http://localhost:8080
VECTOR_DB_API_KEY=your-pinecone-api-key
VECTOR_DB_NAMESPACE=ircc-documents

# LLM Services
OPENAI_API_KEY=your-openai-api-key
ANTHROPIC_API_KEY=your-anthropic-api-key
OPENAI_API_BASE=https://api.openai.com/v1
ANTHROPIC_API_BASE=https://api.anthropic.com

# On-Premises Model Configuration
ON_PREM_MODEL_ENABLED=false
ON_PREM_MODEL_ENDPOINT=http://localhost:8001

# Feature Flags
ENABLE_RETRIEVAL_AUGMENTATION=true
ENABLE_CONTENT_FILTERING=true
ENABLE_EXPLANATION=true

# Performance
MAX_CONCURRENT_REQUESTS=100
REQUEST_TIMEOUT_SECONDS=30

# Logging
LOG_LEVEL=INFO
ENABLE_AUDIT_LOGGING=true

# IRCC System Integration
GCDOCS_API_ENDPOINT=
GCMS_API_ENDPOINT=
DYNAMICS_API_ENDPOINT=

# On-Premises Model Configuration
ON_PREM_MODEL_ENABLED=true
ON_PREM_MODEL_ENDPOINT=http://localhost:8001

# On-Premises Model Endpoints (override defaults in config.py)
# Uncomment and modify as needed
# LLAMA_7B_ENDPOINT=http://llama-vm.canadacentral.azure.com:8000/v1
# LLAMA_70B_ENDPOINT=http://llama-vm.canadacentral.azure.com:8001/v1
# DEEPSEEK_7B_ENDPOINT=http://deepseek-vm.canadacentral.azure.com:8000/v1
# DEEPSEEK_CODER_ENDPOINT=http://deepseek-vm.canadacentral.azure.com:8001/v1