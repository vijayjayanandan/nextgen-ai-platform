# =============================================================================
# IRCC AI Platform - Environment Configuration
# =============================================================================

# Application Settings
API_V1_STR=/api/v1
PROJECT_NAME=IRCC AI Platform
ENVIRONMENT=development
DEBUG=false

# Security
SECRET_KEY=your-secret-key-here
ACCESS_TOKEN_EXPIRE_MINUTES=480
ALGORITHM=HS256
ALLOWED_HOSTS=["*"]

# Database Configuration
POSTGRES_SERVER=localhost
POSTGRES_USER=ircc_user
POSTGRES_PASSWORD=your_password
POSTGRES_DB=ircc_ai_platform
POSTGRES_PORT=5432

# Vector Database Configuration (Legacy - Qdrant is now the primary vector DB)
VECTOR_DB_TYPE=qdrant
VECTOR_DB_URI=
VECTOR_DB_API_KEY=
VECTOR_DB_NAMESPACE=ircc-documents

# Qdrant Configuration (Primary Vector Database)
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_API_KEY=your-qdrant-api-key
QDRANT_COLLECTION_NAME=documents
QDRANT_MEMORY_COLLECTION=conversation_memory
QDRANT_TIMEOUT=30

# =============================================================================
# LLM PROVIDER CONFIGURATION (Choose your provider)
# =============================================================================

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key
OPENAI_API_BASE=https://api.openai.com/v1

# Anthropic Configuration
ANTHROPIC_API_KEY=your-anthropic-api-key
ANTHROPIC_API_BASE=https://api.anthropic.com

# On-Premises Model Configuration (Ollama)
ON_PREM_MODEL_ENABLED=true
ON_PREM_MODEL_ENDPOINT=http://localhost:11434

# =============================================================================
# RAG MODEL CONFIGURATION (LLM-Agnostic)
# =============================================================================

# Option 1: Use Local Models (Ollama)
RAG_QUERY_ANALYSIS_MODEL=mistral:7b
RAG_GENERATION_MODEL=deepseek-coder:6.7b
RAG_RERANKING_MODEL=mistral:7b
RAG_MEMORY_RETRIEVAL_MODEL=mistral:7b
RAG_CITATION_MODEL=mistral:7b

# Option 2: Use OpenAI Models
# RAG_QUERY_ANALYSIS_MODEL=gpt-3.5-turbo
# RAG_GENERATION_MODEL=gpt-4
# RAG_RERANKING_MODEL=gpt-3.5-turbo
# RAG_MEMORY_RETRIEVAL_MODEL=gpt-3.5-turbo
# RAG_CITATION_MODEL=gpt-3.5-turbo

# Option 3: Use Anthropic Models
# RAG_QUERY_ANALYSIS_MODEL=claude-3-haiku-20240307
# RAG_GENERATION_MODEL=claude-3-sonnet-20240229
# RAG_RERANKING_MODEL=claude-3-haiku-20240307
# RAG_MEMORY_RETRIEVAL_MODEL=claude-3-haiku-20240307
# RAG_CITATION_MODEL=claude-3-haiku-20240307

# Option 4: Mixed Provider Setup (Advanced)
# RAG_QUERY_ANALYSIS_MODEL=mistral:7b          # Fast local model for analysis
# RAG_GENERATION_MODEL=gpt-4                   # High-quality cloud model for generation
# RAG_RERANKING_MODEL=claude-3-haiku-20240307  # Efficient cloud model for reranking
# RAG_MEMORY_RETRIEVAL_MODEL=mistral:7b        # Local model for memory
# RAG_CITATION_MODEL=mistral:7b                # Local model for citations

# =============================================================================
# EMBEDDING CONFIGURATION
# =============================================================================

# Embedding Model Type
EMBEDDING_MODEL_TYPE=local
LOCAL_EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_CACHE_SIZE=1000
EMBEDDING_BATCH_SIZE=32
EMBEDDING_DEVICE=cpu

# =============================================================================
# FEATURE FLAGS
# =============================================================================

ENABLE_RETRIEVAL_AUGMENTATION=true
ENABLE_CONTENT_FILTERING=true
ENABLE_EXPLANATION=false
ENABLE_FUNCTION_CALLING=false

# PII Filtering
ENABLE_PII_FILTERING=true
PII_RISK_THRESHOLD=0.7
ENABLE_ML_PII_DETECTION=false
DEFAULT_ANONYMIZATION_METHOD=tokenization
ENABLE_REVERSIBLE_ANONYMIZATION=true
PII_PROCESSING_TIMEOUT_SECONDS=5
ENABLE_PII_AUDIT_LOGGING=true

# Performance Settings
MAX_CONCURRENT_REQUESTS=100
REQUEST_TIMEOUT_SECONDS=30

# Logging
LOG_LEVEL=INFO
ENABLE_AUDIT_LOGGING=true

# =============================================================================
# IRCC SYSTEM INTEGRATION (Optional)
# =============================================================================

GCDOCS_API_ENDPOINT=https://your-gcdocs-endpoint
GCMS_API_ENDPOINT=https://your-gcms-endpoint
DYNAMICS_API_ENDPOINT=https://your-dynamics-endpoint
