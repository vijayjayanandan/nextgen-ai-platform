version: '3.8'

services:
  api:
    build: .
    container_name: ircc-ai-platform-api
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    volumes:
      - .:/app
      - ./storage:/app/storage
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      - POSTGRES_SERVER=db
    networks:
      - ircc-network
    depends_on:
      - db
      - vector-db

  db:
    image: postgres:14-alpine
    container_name: ircc-ai-platform-db
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    env_file:
      - .env
    environment:
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_DB=${POSTGRES_DB}
    networks:
      - ircc-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 5s
      timeout: 5s
      retries: 5

  vector-db:
    image: pinecone/pinecone-tester:latest
    container_name: ircc-ai-platform-vector-db
    ports:
      - "8080:8080"
    networks:
      - ircc-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Optional: Add an on-premises model service for secure inference
  # on-prem-inference:
  #   build: ./on-prem-inference
  #   container_name: ircc-ai-platform-inference
  #   ports:
  #     - "8001:8001"
  #   volumes:
  #     - ./models:/models
  #   networks:
  #     - ircc-network
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: 1
  #             capabilities: [gpu]

networks:
  ircc-network:
    driver: bridge

volumes:
  postgres_data: